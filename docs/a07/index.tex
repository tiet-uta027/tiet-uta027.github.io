% Created 2025-04-30 Wed 05:39
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{parskip}
\author{Raghav B. Venkataramaiyer}
\date{Mar '25}
\title{Assignment 07 : YOLO\\\medskip
\large UTA027 : Artificial Intelligence}
\hypersetup{
 pdfauthor={Raghav B. Venkataramaiyer},
 pdftitle={Assignment 07 : YOLO},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.4 (Org mode 9.6.24)}, 
 pdflang={English}}
\begin{document}

\maketitle
A07 : Object Detection with YOLO
5-May/12-May


\section{Introduction}
\label{sec:org8d55e70}
\subsection{Background}
\label{sec:orgfb45e1b}

Object detection is a computer vision technique that
identifies and locates objects within images or
videos.   It goes beyond image classification by drawing
bounding boxes around detected objects, enabling
machines to "see" and understand their
environment.   This is crucial for applications like
autonomous driving, surveillance, robotics, and medical
imaging, where identifying object locations is
essential for decision-making and automation.

The YOLO (You Only Look Once) family is a popular
series of object detection models known for their speed
and efficiency.  YOLOv8 is a cutting-edge version that
offers state-of-the-art performance.

YOLO models are particularly well-suited for this task
because they process the entire image in a single pass
through the neural network.  This design choice makes
them significantly faster than other object detection
methods, enabling real-time performance.  Despite their
speed, YOLO models, especially YOLOv8, achieve high
accuracy, making them ideal for applications requiring
both speed and precision.

\subsection{Learning Objectives}
\label{sec:org4192d54}
\begin{enumerate}
\item Understand the YOLO architecture.
\item Set up a development environment for YOLO.
\item Prepare a dataset for YOLO training.
\item Train a pre-trained YOLO model on a custom dataset.
\item Evaluate the performance of a trained YOLO model.
\item Perform object detection on images/videos using the
trained model.
\end{enumerate}
\subsection{Dataset}
\label{sec:org9b22834}
Use the Pascal \href{http://host.robots.ox.ac.uk/pascal/VOC/}{VOC Dataset} which is available off the
shelf with both PyTorch and TensorFlow ecosystem.

The PASCAL VOC dataset is a standard dataset for object detection tasks. It defines a specific set of object classes that models are trained to detect. The classes in the PASCAL VOC dataset are:

\begin{description}
\item[{Person}] \texttt{person}
\item[{Animal}] \texttt{bird}, \texttt{cat}, \texttt{cow}, \texttt{dog}, \texttt{horse},
\texttt{sheep}
\item[{Vehicle}] \texttt{aeroplane}, \texttt{bicycle}, \texttt{boat}, \texttt{bus},
\texttt{car}, \texttt{motorbike}, \texttt{train}
\item[{Indoor}] \texttt{bottle}, \texttt{chair}, \texttt{dining table}, \texttt{potted
  plant}, \texttt{sofa}, \texttt{tv/monitor}
\end{description}

Dataset preparation and annotation are crucial for the
PASCAL VOC dataset's effectiveness in training robust
object detection models. High-quality annotations,
including accurate bounding boxes and class labels,
enable models to learn precise object locations and
categories. Consistent annotation across the dataset
ensures that models generalize well to unseen images.

Proper dataset preparation, such as splitting the data
into training, validation, and test sets, is essential
for evaluating model performance and preventing
over-fitting.

\subsection{Software and Libraries}
\label{sec:org799282d}

\begin{enumerate}
\item Python 3.x
\item PyTorch or TensorFlow (specify your framework of
choice).
\item \texttt{torchvision} (if using PyTorch) or
\texttt{tensorflow-datasets} (if using TensorFlow).
\item \texttt{ultralytics} (for YOLOv5 or v8).
\item Recommended: Using a GPU for training.
\end{enumerate}

\section{Tasks}
\label{sec:org6d07aff}
Starter Code: \href{https://gist.github.com/bvraghav/325de78ce4a705f12e940c7e29a2b06e}{[IPython Notebook on Gist]​}

\subsection{Task 1: Training the YOLO Model}
\label{sec:orge31b7fc}
\begin{enumerate}
\item Train the YOLO Model on the VOC Dataset.
\item Pay special attention to training configuration,
\href{https://docs.ultralytics.com/modes/train/\#train-settings}{documented here}, or \href{https://github.com/ultralytics/ultralytics/blob/main/ultralytics/cfg/default.yaml}{here}, and also listed under the
title ``Ref \texttt{model.train} options,'' in the starter
code.
\item Modify/ Update it to achieve better performance.
\end{enumerate}

\subsection{Task 2: Model Evaluation}
\label{sec:orgf001a21}
\begin{enumerate}
\item Evaluate the model under the following metrics:
\begin{itemize}
\item Precision
\item Recall
\item Intersection over Union (IoU)
\item Mean Average Precision (mAP)
\end{itemize}
The candidates are encouraged to use library
functions \emph{e.g.} \href{https://pytorch.org/torcheval/stable/torcheval.metrics.html}{PyTorch Eval Library}, instead of
rolling off their own implementations.
\item Analyse the results and discuss the model's
strengths and weaknesses.
\item Explain the confusion matrix.
\end{enumerate}
\subsection{Task 3: Inference and Visualization}
\label{sec:org2a7c6af}
\begin{enumerate}
\item Capture 10-20 images from ``your daily life'' to
qualitatively assess the performance of your model.
\item Visualise the results.
\item Analyse the results.
\end{enumerate}
\subsection{Tips}
\label{sec:org2e63696}
\begin{enumerate}
\item You are encouraged to train the model in multiple
runs successively improving upon it by parts,
instead of a single pass.
\item Remember to \href{https://colab.research.google.com/notebooks/io.ipynb}{save the model in a persistent storage
device}, lest your endeavours be in vain.
\item Consider \href{https://docs.ultralytics.com/modes/train/\#resuming-interrupted-trainings}{to resume training} from an earlier
checkpoint.  Remember that your runtime might be
limited with free cloud compute!  \emph{E.g.} on Google
Colab you may monitor the estimated available
runtime under ``View Resources.''
\end{enumerate}
\section{Submission}
\label{sec:org5d0f536}
\begin{itemize}
\item Code files (Python scripts or Jupiter Notebooks)
\item A report (in PDF format) that includes:
\begin{itemize}
\item Introduction
\item Methodology (explaining the data preparation,
training process, and evaluation methods)
\item Results (including tables and figures showing the
evaluation metrics)
\item Discussion (analysing the results, discussing
challenges, and suggesting future improvements)
\end{itemize}
\item Trained model weights.
\end{itemize}
\section{Additional Tips for Students}
\label{sec:orgcf18b23}
\begin{itemize}
\item Provide links to relevant documentation and
tutorials that have been of help.
\item You are encouraged to use version control (Git).
\item Use a consistent coding style.
\item Comment the code clearly.
\end{itemize}
\end{document}
